'use client'

import { useEffect, useRef, useState, Suspense } from 'react'
import { useRouter, useSearchParams } from 'next/navigation'
import { Question, FeedbackResult, PracticePhase, TaskType } from '@/lib/types'
import { getRandomQuestion, getWeightedQuestion, TASK_TYPE_LABELS } from '@/lib/questions'
import { addSession, getScoreHistory } from '@/lib/storage'
import Timer from '@/components/Timer'
import Recorder from '@/components/Recorder'
import HighlightedText from '@/components/HighlightedText'
import FeedbackPanel from '@/components/FeedbackPanel'

function PracticeContent() {
  const router = useRouter()
  const params = useSearchParams()
  const type = params.get('type') as TaskType | 'random' | null
  const level = params.get('level') || 'IH (Intermediate High)'

  const [question, setQuestion] = useState<Question | null>(null)
  const [phase, setPhase] = useState<PracticePhase>('idle')
  const [transcript, setTranscript] = useState('')
  const [audioUrl, setAudioUrl] = useState('')
  const [feedback, setFeedback] = useState<FeedbackResult | null>(null)
  const [error, setError] = useState<string | null>(null)
  const [isLoading, setIsLoading] = useState(false)
  const [processingMsg, setProcessingMsg] = useState('AIê°€ ë‹µë³€ì„ ë¶„ì„í•˜ëŠ” ì¤‘...')
  const [imageDesc, setImageDesc] = useState<string | null>(null)
  const [imageDescLoading, setImageDescLoading] = useState(false)
  const [promptAudioUrl, setPromptAudioUrl] = useState<string | null>(null)
  const [promptAudioLoading, setPromptAudioLoading] = useState(false)
  const [showPromptText, setShowPromptText] = useState(false)
  const transcriptRef = useRef('')
  const promptAudioRef = useRef<HTMLAudioElement | null>(null)

  // Load question on mount
  useEffect(() => {
    const history = getScoreHistory()
    let q: Question
    if (!type || type === 'random') {
      q = getWeightedQuestion(history)
    } else {
      q = getRandomQuestion(type)
    }
    setQuestion(q)
  }, [type])

  // Auto-generate TTS for propose_solution and express_opinion prompts
  useEffect(() => {
    if (!question || (question.type !== 'propose_solution' && question.type !== 'express_opinion')) return
    setPromptAudioUrl(null)
    setShowPromptText(false)
    setPromptAudioLoading(true)
    fetch('/api/tts', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ text: question.prompt }),
    })
      .then((r) => r.blob())
      .then((blob) => {
        const url = URL.createObjectURL(blob)
        setPromptAudioUrl(url)
      })
      .catch(() => setPromptAudioUrl(null))
      .finally(() => setPromptAudioLoading(false))
  }, [question])

  // Auto-describe image when describe_picture question loads
  useEffect(() => {
    if (!question || question.type !== 'describe_picture' || !question.imageUrl) return
    setImageDesc(null)
    setImageDescLoading(true)
    fetch('/api/describe-image', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ imageUrl: question.imageUrl }),
    })
      .then((r) => r.json())
      .then((data) => setImageDesc(data.description || null))
      .catch(() => setImageDesc(null))
      .finally(() => setImageDescLoading(false))
  }, [question])

  function startPrep() {
    setPhase('prep')
    setTranscript('')
    setFeedback(null)
    setError(null)
  }

  function startRecording() {
    setPhase('recording')
  }

  function stopRecording() {
    setPhase('processing')
    setProcessingMsg('Whisperë¡œ ìŒì„± ë³€í™˜ ì¤‘...')
    // handleAudioBlob will be called by Recorder when audio is ready
  }

  async function handleAudioBlob(blob: Blob) {
    let finalText = transcriptRef.current.trim()

    // Try Whisper first
    try {
      const fd = new FormData()
      fd.append('audio', new File([blob], 'recording.webm', { type: 'audio/webm' }))
      const res = await fetch('/api/transcribe', { method: 'POST', body: fd })
      if (res.ok) {
        const data = await res.json()
        if (data.transcript?.trim()) {
          finalText = data.transcript.trim()
          setTranscript(finalText)
        }
      }
    } catch {
      // fall through to Web Speech fallback
    }

    if (finalText.length > 0) {
      setProcessingMsg('Claudeê°€ ë¬¸ë²•ì„ ë¶„ì„í•˜ëŠ” ì¤‘...')
      submitForFeedback(finalText)
    } else {
      setError('ìŒì„±ì´ ì¸ì‹ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜ ì§ì ‘ ì…ë ¥í•´ ì£¼ì„¸ìš”.')
      setPhase('recording')
    }
  }

  async function submitForFeedback(text: string) {
    if (!question) return
    setIsLoading(true)
    setError(null)

    try {
      const res = await fetch('/api/feedback', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ question, transcript: text, targetLevel: level }),
      })

      if (!res.ok) {
        const data = await res.json()
        throw new Error(data.error || 'API ì˜¤ë¥˜')
      }

      const fb = await res.json() as FeedbackResult
      setFeedback(fb)
      setPhase('done')

      // Save session
      addSession({
        id: crypto.randomUUID(),
        date: new Date().toISOString(),
        question,
        transcript: text,
        feedback: fb,
      })
    } catch (e) {
      setError((e as Error).message || 'í”¼ë“œë°± ìƒì„± ì‹¤íŒ¨. API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.')
      setPhase('recording')
    } finally {
      setIsLoading(false)
    }
  }

  function nextQuestion() {
    const history = getScoreHistory()
    let q: Question
    if (!type || type === 'random') {
      q = getWeightedQuestion(history)
    } else {
      q = getRandomQuestion(type)
    }
    setQuestion(q)
    setPhase('idle')
    setTranscript('')
    setFeedback(null)
    setError(null)
    setAudioUrl('')
    setImageDesc(null)
    setPromptAudioUrl(null)
    setShowPromptText(false)
  }

  if (!question) {
    return (
      <div className="flex items-center justify-center h-40">
        <div className="w-8 h-8 border-4 border-blue-500 border-t-transparent rounded-full animate-spin" />
      </div>
    )
  }

  return (
    <div className="space-y-6">
      {/* Question card */}
      <div className="bg-white border border-gray-200 rounded-2xl p-5 shadow-sm">
        <div className="flex items-center gap-2 mb-3">
          <span className="text-xs bg-blue-100 text-blue-700 px-2 py-0.5 rounded-full font-medium">
            {TASK_TYPE_LABELS[question.type]}
          </span>
          <span className={`text-xs px-2 py-0.5 rounded-full font-medium ${
            question.difficulty === 'easy'
              ? 'bg-green-100 text-green-700'
              : question.difficulty === 'medium'
              ? 'bg-yellow-100 text-yellow-700'
              : 'bg-red-100 text-red-700'
          }`}>
            {question.difficulty === 'easy' ? 'ì‰¬ì›€' : question.difficulty === 'medium' ? 'ì¤‘ê°„' : 'ì–´ë ¤ì›€'}
          </span>
          {question.tags.slice(0, 2).map((tag) => (
            <span key={tag} className="text-xs bg-gray-100 text-gray-500 px-2 py-0.5 rounded-full">
              #{tag}
            </span>
          ))}
        </div>

        {/* propose_solution / express_opinion: ìŒì„± í”Œë ˆì´ì–´ */}
        {(question.type === 'propose_solution' || question.type === 'express_opinion') ? (
          <div className="mt-1 space-y-3">
            {question.type === 'propose_solution' ? (
              <div className="bg-orange-50 border border-orange-200 rounded-xl p-4 space-y-3">
                <div className="flex items-center gap-2">
                  <span className="text-orange-500 text-lg">ğŸ“</span>
                  <p className="text-xs font-semibold text-orange-700 uppercase tracking-wide">ìŒì„± ë©”ì‹œì§€</p>
                </div>
                {promptAudioLoading && (
                  <div className="flex items-center gap-2 text-sm text-orange-600">
                    <span className="w-4 h-4 border-2 border-orange-300 border-t-orange-500 rounded-full animate-spin" />
                    ìŒì„± ìƒì„± ì¤‘...
                  </div>
                )}
                {promptAudioUrl && (
                  <audio ref={promptAudioRef} controls autoPlay src={promptAudioUrl} className="w-full h-10" />
                )}
                <button onClick={() => setShowPromptText((v) => !v)} className="text-xs text-orange-600 underline">
                  {showPromptText ? 'í…ìŠ¤íŠ¸ ìˆ¨ê¸°ê¸°' : 'í…ìŠ¤íŠ¸ë¡œ ë³´ê¸°'}
                </button>
                {showPromptText && (
                  <p className="text-gray-700 text-sm leading-relaxed">{question.prompt}</p>
                )}
              </div>
            ) : (
              <div className="bg-indigo-50 border border-indigo-200 rounded-xl p-4 space-y-3">
                <div className="flex items-center gap-2">
                  <span className="text-indigo-500 text-lg">ğŸ§</span>
                  <p className="text-xs font-semibold text-indigo-700 uppercase tracking-wide">í† í”½ ë“£ê¸°</p>
                </div>
                {promptAudioLoading && (
                  <div className="flex items-center gap-2 text-sm text-indigo-600">
                    <span className="w-4 h-4 border-2 border-indigo-300 border-t-indigo-500 rounded-full animate-spin" />
                    ìŒì„± ìƒì„± ì¤‘...
                  </div>
                )}
                {promptAudioUrl && (
                  <audio ref={promptAudioRef} controls autoPlay src={promptAudioUrl} className="w-full h-10" />
                )}
                <button onClick={() => setShowPromptText((v) => !v)} className="text-xs text-indigo-600 underline">
                  {showPromptText ? 'í…ìŠ¤íŠ¸ ìˆ¨ê¸°ê¸°' : 'í…ìŠ¤íŠ¸ë¡œ ë³´ê¸°'}
                </button>
                {showPromptText && (
                  <p className="text-gray-700 text-sm leading-relaxed">{question.prompt}</p>
                )}
              </div>
            )}
          </div>
        ) : (
          <p className="text-gray-700 leading-relaxed font-medium">{question.prompt}</p>
        )}

        {/* Read aloud passage */}
        {question.passage && (
          <div className="mt-3 bg-blue-50 border border-blue-200 rounded-xl p-4">
            <p className="text-xs text-blue-500 uppercase tracking-wide mb-1">ì½ì„ í…ìŠ¤íŠ¸</p>
            <p className="text-gray-800 leading-relaxed">{question.passage}</p>
          </div>
        )}

        {/* Picture: photo + AI-generated description */}
        {question.type === 'describe_picture' && (
          <div className="mt-3 space-y-2">
            {question.imageUrl && (
              // eslint-disable-next-line @next/next/no-img-element
              <img
                src={question.imageUrl}
                alt="ë¬˜ì‚¬í•  ì‚¬ì§„"
                className="w-full rounded-xl border border-gray-200 object-cover"
                style={{ maxHeight: '280px' }}
                onError={(e) => { (e.currentTarget as HTMLImageElement).style.display = 'none' }}
              />
            )}
            {imageDescLoading && (
              <div className="flex items-center gap-2 text-xs text-gray-400 px-1">
                <span className="w-3 h-3 border-2 border-gray-300 border-t-blue-400 rounded-full animate-spin" />
                ì‚¬ì§„ ë¶„ì„ ì¤‘...
              </div>
            )}
            {imageDesc && (
              <div className="bg-amber-50 border border-amber-200 rounded-xl p-3">
                <p className="text-xs text-amber-600 uppercase tracking-wide mb-1">ì¥ë©´ ì„¤ëª… (ì°¸ê³ ìš©)</p>
                <p className="text-gray-700 text-sm leading-relaxed">{imageDesc}</p>
              </div>
            )}
          </div>
        )}

        <div className="flex gap-4 mt-4 text-xs text-gray-400">
          <span>ì¤€ë¹„ {question.prepTime}ì´ˆ</span>
          <span>ë‹µë³€ {question.answerTime}ì´ˆ</span>
        </div>
      </div>

      {/* Phase: idle */}
      {phase === 'idle' && (
        <button
          onClick={startPrep}
          className="w-full bg-blue-600 hover:bg-blue-700 text-white py-4 rounded-2xl font-bold text-lg transition-colors"
        >
          ì¤€ë¹„ ì‹œì‘ â†’
        </button>
      )}

      {/* Phase: prep */}
      {phase === 'prep' && (
        <div className="bg-white border border-gray-200 rounded-2xl p-6 text-center space-y-4">
          <p className="text-gray-500 text-sm">ì¤€ë¹„ ì‹œê°„ ë™ì•ˆ ë‹µë³€ì„ êµ¬ìƒí•˜ì„¸ìš”</p>
          <Timer
            seconds={question.prepTime}
            onComplete={startRecording}
            label="ì¤€ë¹„"
            colorClass="text-blue-600"
          />
          <button
            onClick={startRecording}
            className="text-sm text-blue-600 underline"
          >
            ë°”ë¡œ ë…¹ìŒ ì‹œì‘
          </button>
        </div>
      )}

      {/* Phase: recording â€” Recorder stays mounted during processing for mr.onstop to fire */}
      {(phase === 'recording' || phase === 'processing') && (
        <div className={phase === 'processing' ? 'hidden' : 'bg-white border border-gray-200 rounded-2xl p-6 space-y-4'}>
          {phase === 'recording' && (
            <div className="flex justify-center">
              <Timer
                seconds={question.answerTime}
                onComplete={stopRecording}
                label="ë‹µë³€"
                colorClass="text-red-500"
              />
            </div>
          )}

          <Recorder
            active={phase === 'recording'}
            onTranscriptChange={(text) => {
              transcriptRef.current = text
              setTranscript(text)
            }}
            onAudioReady={setAudioUrl}
            onAudioBlobReady={handleAudioBlob}
          />

          {phase === 'recording' && (
            <>
              {error && (
                <p className="text-sm text-red-600 bg-red-50 px-3 py-2 rounded-lg">{error}</p>
              )}

              <button
                onClick={stopRecording}
                className="w-full bg-red-500 hover:bg-red-600 text-white py-3 rounded-xl font-semibold transition-colors"
              >
                ë…¹ìŒ ì™„ë£Œ / ë¶„ì„ ìš”ì²­
              </button>

              {/* Manual submit if STT fails */}
              {transcript.length === 0 && (
                <div>
                  <p className="text-xs text-gray-400 mb-1">ìŒì„± ì¸ì‹ì´ ì•ˆ ë˜ë‚˜ìš”? ì§ì ‘ ì…ë ¥:</p>
                  <textarea
                    className="w-full border border-gray-300 rounded-xl p-3 text-sm resize-none focus:outline-none focus:ring-2 focus:ring-blue-400"
                    rows={3}
                    placeholder="ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”..."
                    onChange={(e) => {
                      transcriptRef.current = e.target.value
                      setTranscript(e.target.value)
                    }}
                  />
                  {transcript.trim() && (
                    <button
                      onClick={() => submitForFeedback(transcript)}
                      className="mt-2 w-full bg-blue-600 text-white py-2 rounded-xl text-sm font-medium"
                    >
                      ì´ í…ìŠ¤íŠ¸ë¡œ ë¶„ì„
                    </button>
                  )}
                </div>
              )}
            </>
          )}
        </div>
      )}

      {/* Phase: processing */}
      {phase === 'processing' && (
        <div className="bg-white border border-gray-200 rounded-2xl p-8 text-center space-y-3">
          <div className="w-10 h-10 border-4 border-blue-500 border-t-transparent rounded-full animate-spin mx-auto" />
          <p className="text-gray-600 font-medium">{processingMsg}</p>
          <p className="text-gray-400 text-sm">ë¬¸ë²• ì˜¤ë¥˜, í‘œí˜„, ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ê³  ìˆì–´ìš”</p>
        </div>
      )}

      {/* Phase: done */}
      {phase === 'done' && feedback && (
        <div className="space-y-6">
          {/* Transcript with highlights */}
          <div className="bg-white border border-gray-200 rounded-2xl p-5 space-y-3">
            <h2 className="font-bold text-gray-800">ë‚´ ë‹µë³€ ì›ë¬¸</h2>
            <HighlightedText text={transcript} errors={feedback.errors} />
          </div>

          {/* Feedback panel */}
          <FeedbackPanel feedback={feedback} />

          {/* Audio playback */}
          {audioUrl && (
            <div className="bg-white border border-gray-200 rounded-2xl p-4 flex items-center gap-3">
              <span className="text-sm text-gray-500 shrink-0">ë‚´ ë…¹ìŒ:</span>
              <audio controls src={audioUrl} className="flex-1 h-8" />
            </div>
          )}

          {/* Actions */}
          <div className="flex gap-3">
            <button
              onClick={nextQuestion}
              className="flex-1 bg-blue-600 hover:bg-blue-700 text-white py-3 rounded-xl font-semibold transition-colors"
            >
              ë‹¤ìŒ ë¬¸ì œ â†’
            </button>
            <button
              onClick={() => router.push('/')}
              className="px-4 bg-gray-100 hover:bg-gray-200 text-gray-600 py-3 rounded-xl font-medium transition-colors"
            >
              í™ˆìœ¼ë¡œ
            </button>
          </div>
        </div>
      )}
    </div>
  )
}

export default function PracticePage() {
  return (
    <Suspense fallback={
      <div className="flex items-center justify-center h-40">
        <div className="w-8 h-8 border-4 border-blue-500 border-t-transparent rounded-full animate-spin" />
      </div>
    }>
      <PracticeContent />
    </Suspense>
  )
}
